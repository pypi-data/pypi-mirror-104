{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
      }
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "    Model: {{ SLAI_MODEL_NAME }}\n",
        "    Created: {{ SLAI_MODEL_CREATED_AT }}\n",
        "\n",
        "    This notebook was autogenerated using the slai command line interface\n",
        "'''\n",
        "\n",
        "import os\n",
        "\n",
        "!pip install awscli\n",
        "!pip install git+https://dca17ed5ca783676bf866111f72f749227d62d39@github.com/luke-lombardi/slai.git\n",
        "!pip install fastai\n",
        "\n",
        "# Note: These environmental variables are required for saving artifacts and datasets, do not modify.\n",
        "os.environ['SLAI_PROJECT_PATH'] = '/content/drive/MyDrive/slai-{{SLAI_PROJECT_NAME}}-{{SLAI_PROJECT_ID}}'\n",
        "os.environ['SLAI_NOTEBOOK_PATH'] = '/content/drive/MyDrive/slai-{{SLAI_PROJECT_NAME}}-{{SLAI_PROJECT_ID}}/{{SLAI_MODEL_NAME}}/{{SLAI_MODEL_NAME}}.ipynb'\n",
        "os.environ['SLAI_TRAINER_PATH'] = '/content/drive/MyDrive/slai-{{SLAI_PROJECT_NAME}}-{{SLAI_PROJECT_ID}}/{{SLAI_MODEL_NAME}}/{{SLAI_MODEL_NAME}}.py'\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = '/content/drive/MyDrive/slai-{{SLAI_PROJECT_NAME}}-{{SLAI_PROJECT_ID}}/awscli.ini'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keep\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import slai\n",
        "\n",
        "model_version = slai.model_version(model_name=\"{{SLAI_MODEL_NAME}}\", project_name=\"{{SLAI_PROJECT_NAME}}\", model_version_id=\"{{SLAI_MODEL_VERSION_ID}}\")\n",
        "\n",
        "dataset = model_version.dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keep\n",
        "\n",
        "# Create a model\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Net()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Any local filesystem changes can be backed up to S3 using dataset.save()\n",
        "dataset.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keep\n",
        "\n",
        "# Export your model into the slai backend as a model artifact\n",
        "model_version.save(model=model)"
      ]
    }
  ]
}